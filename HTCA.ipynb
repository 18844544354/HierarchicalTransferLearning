{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tools\n",
    "import tca\n",
    "import sklearn\n",
    "import random\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# A = pd.read_csv(\"/cs/home/ms383/Dissertation/data/A.csv\", header=None) \n",
    "# B = pd.read_csv(\"/cs/home/ms383/Dissertation/data/B.csv\", header=None) \n",
    "# C = pd.read_csv(\"/cs/home/ms383/Dissertation/data/C.csv\", header=None) \n",
    "# AB_sim = pd.read_csv(\"/cs/home/ms383/Dissertation/data/Sensor_Sim_AB.csv\", header=None, sep = '\\t')\n",
    "# BC_sim = pd.read_csv(\"/cs/home/ms383/Dissertation/data/Sensor_Sim_BC.csv\", header=None, sep = '\\t')\n",
    "# AC_sim = pd.read_csv(\"/cs/home/ms383/Dissertation/data/Sensor_Sim_AC.csv\", header=None, sep = '\\t')\n",
    "\n",
    "A = pd.read_csv(\"D:/workspace/jupyter/Dissertation/data/A.csv\", header=None) \n",
    "B = pd.read_csv(\"D:/workspace/jupyter/Dissertation/data/B.csv\", header=None) \n",
    "C = pd.read_csv(\"D:/workspace/jupyter/Dissertation/data/C.csv\", header=None) \n",
    "AB_sim = pd.read_csv(\"D:/workspace/jupyter/Dissertation/data/Sensor_Sim_AB.csv\", header=None, sep = '\\t')\n",
    "BC_sim = pd.read_csv(\"D:/workspace/jupyter/Dissertation/data/Sensor_Sim_BC.csv\", header=None, sep = '\\t')\n",
    "AC_sim = pd.read_csv(\"D:/workspace/jupyter/Dissertation/data/Sensor_Sim_AC.csv\", header=None, sep = '\\t')\n",
    "\n",
    "# A = pd.read_csv(\"/Users/fred/Desktop/Dissertation/Dissertation/data/A.csv\", header=None) \n",
    "# B = pd.read_csv(\"/Users/fred/Desktop/Dissertation/Dissertation/data/B.csv\", header=None) \n",
    "# C = pd.read_csv(\"/Users/fred/Desktop/Dissertation/Dissertation/data/C.csv\", header=None) \n",
    "# AB_sim = pd.read_csv(\"/Users/fred/Desktop/Dissertation/Dissertation/data/Sensor_Sim_AB.csv\", header=None, sep = '\\t')\n",
    "# BC_sim = pd.read_csv(\"/Users/fred/Desktop/Dissertation/Dissertation/data/Sensor_Sim_BC.csv\", header=None, sep = '\\t')\n",
    "# AC_sim = pd.read_csv(\"/Users/fred/Desktop/Dissertation/Dissertation/data/Sensor_Sim_AC.csv\", header=None, sep = '\\t')\n",
    "\n",
    "x_a = np.array(A.values[:, 1:A.shape[1]])\n",
    "y_a = np.array(np.transpose([A.values[:, 0]]))\n",
    "x_b = np.array(B.values[:, 1:B.shape[1]])\n",
    "y_b = np.array(np.transpose([B.values[:, 0]]))\n",
    "x_c = np.array(C.values[:, 1:C.shape[1]])\n",
    "y_c = np.array(np.transpose([C.values[:, 0]]))\n",
    "\n",
    "Ab = np.dot(x_a,AB_sim)\n",
    "Ac = np.dot(x_a,AC_sim)\n",
    "Ba = np.dot(x_b,AB_sim.T)\n",
    "Bc = np.dot(x_b,BC_sim)\n",
    "Ca = np.dot(x_c,AC_sim.T)\n",
    "Cb = np.dot(x_c,BC_sim.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'dim':20,\n",
    "           'kerneltype':'rbf',\n",
    "           'kernelparam':1.0,\n",
    "           'mu':1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runhtca(x_src,y_src,x_tar,y_tar):\n",
    "    ################################################################# prepare\n",
    "    tf='TCA'\n",
    "    label_set = np.unique(y_src).astype(int)\n",
    "\n",
    "    #classifiers\n",
    "    ##RF\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf = RandomForestClassifier()\n",
    "    ##KNN\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(5)\n",
    "    ##Bernoulli Naive bayes\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    bnb = sklearn.naive_bayes.BernoulliNB()\n",
    "    ##Gaussian Naive Bayes\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    ##Decision tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dt = sklearn.tree.DecisionTreeClassifier()\n",
    "    ##LogisticRegression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lr = LogisticRegression()\n",
    "    ##SVC\n",
    "    from sklearn.svm import SVC\n",
    "    svc = SVC(C=100)\n",
    "    ##ExtraTreeClassifier\n",
    "    from sklearn.tree import ExtraTreeClassifier\n",
    "    etc = ExtraTreeClassifier()\n",
    "    ##NN\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    nn = MLPClassifier()\n",
    "\n",
    "\n",
    "    ############################################################### voting \n",
    "    # generate model\n",
    "    models = tools.Models(x_src,y_src,x_tar,y_tar)\n",
    "    models.add(rf,'RF')\n",
    "    models.add(lr,'LR')\n",
    "    models.add(svc,'SVC')\n",
    "\n",
    "    models.sort_src(show=False)\n",
    "    label_voting = voting(x_tar.shape[0],\n",
    "                          models.model[0],\n",
    "                          models.model[1],\n",
    "                          models.model[2])\n",
    "\n",
    "    #get residual and candidate\n",
    "    x_tar_residual = []\n",
    "    y_tar_residual = []\n",
    "    x_tar_candidate = []\n",
    "    y_tar_candidate = []\n",
    "    label_candidate = []\n",
    "    #residual\n",
    "    r_index = [i for i in range(x_tar.shape[0]) if (label_voting[i] == -1)]\n",
    "    x_tar_residual = x_tar[r_index,:]\n",
    "    y_tar_residual = y_tar[r_index,:]\n",
    "    label_residual = label_voting[r_index]\n",
    "    #candidate\n",
    "    c_index = [i for i in range(x_tar.shape[0]) if (label_voting[i] != -1)]\n",
    "    x_tar_candidate = x_tar[c_index,:]\n",
    "    y_tar_candidate = y_tar[c_index,:]\n",
    "    label_candidate = label_voting[c_index]\n",
    "    \n",
    "    r = y_tar_candidate.shape[0]/y_tar.shape[0]\n",
    "\n",
    "    ############################################################in-class transfer\n",
    "    x_tar_candidate_new = []\n",
    "    y_tar_candidate_new = []\n",
    "    x_src_new = []\n",
    "    y_src_new = []\n",
    "    x_tar_candidate_old = []\n",
    "    y_tar_candidate_old = []\n",
    "\n",
    "    for i, element in enumerate(label_set):\n",
    "        class_index = label_set[i]\n",
    "        #source data in that class i        \n",
    "        src_index_i = [i for i in range(x_src.shape[0]) if (y_src[i,0] == class_index)]\n",
    "        x_src_i = x_src[src_index_i,:]\n",
    "        y_src_i = y_src[src_index_i,:]\n",
    "        #candidate data in that class i\n",
    "        tar_index_i = [i for i in range(x_tar_candidate.shape[0]) if (label_candidate[i] == class_index)]\n",
    "        x_tar_candidate_i = x_tar_candidate[tar_index_i,:]\n",
    "        y_tar_candidate_i = y_tar_candidate[tar_index_i,:]\n",
    "        if (x_tar_candidate_i != []):\n",
    "            for j in range(x_tar_candidate_i.shape[0]):\n",
    "                x_tar_candidate_old.append(x_tar_candidate_i[j])\n",
    "                y_tar_candidate_old.append(y_tar_candidate_i[j])\n",
    "        ##################TCA\n",
    "        my_tca = tca.TCA(dim=options['dim'],kerneltype=options['kerneltype'], kernelparam=options['kernelparam'], mu=options['mu'])\n",
    "        if (x_tar_candidate_i.shape[0] == 0):\n",
    "            x_tar_candidate_new_i = x_tar_candidate_i\n",
    "    #         x_tar_candidate_i_fake = np.array(random.sample(list(x_src_i),15)) # sample from src to generate fake candidate\n",
    "            x_tar_candidate_i_fake = np.array(random.sample(list(x_tar),50)) #sample from target\n",
    "            x_src_new_i, x_tar_candidate_new_i_fake, x_tar_o = my_tca.fit_transform(x_src_i, x_tar_candidate_i_fake)\n",
    "        else:\n",
    "            x_tar_candidate_i_fake = np.array(random.sample(list(x_tar),80)) # resample to make the class with less candidate more robust\n",
    "            x_src_new_i, x_tar_candidate_new_i, x_tar_o = my_tca.fit_transform(x_src_i, x_tar_candidate_i)\n",
    "        #merge\n",
    "        for j in range(x_src_new_i.shape[0]):\n",
    "            x_src_new.append(np.array(x_src_new_i[j]).reshape((1,options['dim'])))\n",
    "            y_src_new.append(y_src_i[j])\n",
    "        if (x_tar_candidate_new_i.shape[0] != 0):\n",
    "            for j in range(x_tar_candidate_new_i.shape[0]):\n",
    "                x_tar_candidate_new.append(np.array(x_tar_candidate_new_i[j]).reshape((1,options['dim'])))\n",
    "                y_tar_candidate_new.append(y_tar_candidate_i[j])\n",
    "\n",
    "    #change the list to array\n",
    "    x_tar_candidate_old = np.array(x_tar_candidate_old)\n",
    "    y_tar_candidate_old = np.array(y_tar_candidate_old)\n",
    "    x_src_new = np.array(x_src_new).reshape(x_src.shape[0],options['dim'])\n",
    "    y_src_new = np.array(y_src_new)\n",
    "    x_tar_candidate_new = np.array(x_tar_candidate_new).reshape(x_tar_candidate.shape[0],options['dim'])\n",
    "    y_tar_candidate_new = np.array(y_tar_candidate_new)\n",
    "\n",
    "    ########################################################## second annotation\n",
    "    #train model on new candidate   \n",
    "    knn_1 = KNeighborsClassifier(5)\n",
    "    knn_1.fit(x_src_new, y_src_new)\n",
    "    predicted_label_candidate = np.array(knn_1.predict(x_tar_candidate_new)).reshape((-1,1))\n",
    "    acc_candidate = accuracy_score(y_tar_candidate_new, predicted_label_candidate)\n",
    "\n",
    "    #train model on old candidate and predict on residual\n",
    "    knn_2 = KNeighborsClassifier(5)\n",
    "    knn_2.fit(x_tar_candidate_old, predicted_label_candidate)\n",
    "    predicted_label_residual = knn_2.predict(x_tar_residual).reshape((-1,1))\n",
    "    acc_residual = accuracy_score(y_tar_residual, predicted_label_residual)\n",
    "\n",
    "    #get prediction\n",
    "    y_predict = np.vstack((predicted_label_candidate, predicted_label_residual))\n",
    "    #calculate final accuracy\n",
    "    acc_stl = accuracy_score(np.vstack((y_tar_candidate_new, y_tar_residual)), np.vstack((predicted_label_candidate, predicted_label_residual)))\n",
    "\n",
    "    tools.remove_files()#for JDA\n",
    "    return acc_candidate,acc_residual,acc_stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 22) (505, 1) (497, 22) (497, 1)\n"
     ]
    }
   ],
   "source": [
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ab,y_a ,x_b ,y_b , balance=False, z_score=False)\n",
    "print(x_src.shape,y_src.shape,x_tar.shape,y_tar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-B      0.818841   0.674699   0.794769  \n",
      "B-A      0.334311   0.359756   0.342574  \n",
      "B-C      0.634146   0.130435   0.609705  \n",
      "C-B      0.186992   0.600000   0.191147  \n",
      "A-C      0.804819   0.067797   0.713080  \n",
      "C-A      0.544757   0.166667   0.459406  \n"
     ]
    }
   ],
   "source": [
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ab,y_a ,x_b ,y_b , balance=True)\n",
    "a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "print(\"%-8s\"%(\"A-B\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ba, y_b ,x_a ,y_a , balance=True)\n",
    "a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "print(\"%-8s\"%(\"B-A\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Bc, y_b ,x_c ,y_c , balance=True)\n",
    "a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "print(\"%-8s\"%(\"B-C\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Cb, y_c ,x_b ,y_b , balance=True)\n",
    "a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "print(\"%-8s\"%(\"C-B\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ac, y_a ,x_c ,y_c , balance=True)\n",
    "a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "print(\"%-8s\"%(\"A-C\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ca, y_c ,x_a ,y_a , balance=True)\n",
    "a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "print(\"%-8s\"%(\"C-A\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-B      0.818841   0.674699   0.794769  \n",
    "B-A      0.334311   0.359756   0.342574  \n",
    "B-C      0.634146   0.130435   0.609705  \n",
    "C-B      0.186992   0.600000   0.191147  \n",
    "A-C      0.804819   0.067797   0.713080  \n",
    "C-A      0.544757   0.166667   0.459406  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTCA mean of 10 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## balanced unstandarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-B      0.692922   0.674583   0.751509  \n",
      "B-A      0.369874   0.310182   0.363663  \n",
      "B-C      0.633927   0.125892   0.612025  \n",
      "C-B      0.356224   0.152061   0.260463  \n",
      "A-C      0.724072   0.050684   0.610970  \n",
      "C-A      0.563469   0.204470   0.519802  \n"
     ]
    }
   ],
   "source": [
    "seed(123)\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ab,y_a ,x_b ,y_b , balance=True)\n",
    "df = pd.DataFrame(columns=['acc_can','acc_res','acc_stl'])\n",
    "T = 20\n",
    "for i in range(T):\n",
    "    a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "    df = df.append(pd.DataFrame({'acc_can':a,'acc_res':b,'acc_stl':c}, \n",
    "                      index=[i]))\n",
    "a,b,c = df.mean()\n",
    "print(\"%-8s\"%(\"A-B\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ba, y_b ,x_a ,y_a , balance=True)\n",
    "df = pd.DataFrame(columns=['acc_can','acc_res','acc_stl'])\n",
    "for i in range(T):\n",
    "    a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "    df = df.append(pd.DataFrame({'acc_can':a,'acc_res':b,'acc_stl':c}, \n",
    "                      index=[i]))\n",
    "a,b,c = df.mean()\n",
    "print(\"%-8s\"%(\"B-A\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Bc, y_b ,x_c ,y_c , balance=True)\n",
    "df = pd.DataFrame(columns=['acc_can','acc_res','acc_stl'])\n",
    "for i in range(T):\n",
    "    a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "    df = df.append(pd.DataFrame({'acc_can':a,'acc_res':b,'acc_stl':c}, \n",
    "                      index=[i]))\n",
    "a,b,c = df.mean()\n",
    "print(\"%-8s\"%(\"B-C\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Cb, y_c ,x_b ,y_b , balance=True)\n",
    "df = pd.DataFrame(columns=['acc_can','acc_res','acc_stl'])\n",
    "for i in range(T):\n",
    "    a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "    df = df.append(pd.DataFrame({'acc_can':a,'acc_res':b,'acc_stl':c}, \n",
    "                      index=[i]))\n",
    "a,b,c = df.mean()\n",
    "print(\"%-8s\"%(\"C-B\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ac, y_a ,x_c ,y_c , balance=True)\n",
    "df = pd.DataFrame(columns=['acc_can','acc_res','acc_stl'])\n",
    "for i in range(T):\n",
    "    a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "    df = df.append(pd.DataFrame({'acc_can':a,'acc_res':b,'acc_stl':c}, \n",
    "                      index=[i]))\n",
    "a,b,c = df.mean()\n",
    "print(\"%-8s\"%(\"A-C\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n",
    "\n",
    "x_src, y_src, x_tar, y_tar = tools.getdata(Ca, y_c ,x_a ,y_a , balance=True)\n",
    "df = pd.DataFrame(columns=['acc_can','acc_res','acc_stl'])\n",
    "for i in range(T):\n",
    "    a,b,c = runhtca(x_src, y_src, x_tar, y_tar)\n",
    "    df = df.append(pd.DataFrame({'acc_can':a,'acc_res':b,'acc_stl':c}, \n",
    "                      index=[i]))\n",
    "a,b,c = df.mean()\n",
    "print(\"%-8s\"%(\"C-A\"),\n",
    "      \"%-10.6f\"%(a),\n",
    "      \"%-10.6f\"%(b),\n",
    "      \"%-10.6f\"%(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-B      0.658881   0.758998   0.758350  \n",
    "B-A      0.356341   0.295877   0.348911  \n",
    "B-C      0.632276   0.122052   0.613080  \n",
    "C-B      0.417704   0.263826   0.380684  \n",
    "A-C      0.714880   0.071606   0.615401  \n",
    "C-A      0.576425   0.354958   0.543366"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
